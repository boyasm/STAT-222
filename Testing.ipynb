{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#What Results in Death?  \n",
      "##*Analysis of Social Conflict in Africa, 1990&ndash;2011*\n",
      "\n",
      "###Matthew Boyas <br/> STAT 222, MA Capstone <br/> 9 May 2014"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing Suite"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file boyas_test.py\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy as sp\n",
      "import collections as col\n",
      "import statsmodels.api as sm\n",
      "\n",
      "\n",
      "from statsmodels.formula.api import logit, probit, poisson\n",
      "from scipy import stats\n",
      "from scipy.stats import nbinom\n",
      "from sklearn.cross_validation import KFold, cross_val_score\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn import tree\n",
      "from mpl_toolkits.basemap import Basemap\n",
      "from IPython.display import display\n",
      "from IPython.display import HTML\n",
      "\n",
      "# This code was written using Scipy 0.13.3, Numpy 1.6.1, Pandas 0.12.0, XLRD 0.9.2, Matplotlib Basemap 1.0.6, GEOS 3.3.3\n",
      "# It may not be compatibile with other module versions\n",
      "# Code version 14 April 2014\n",
      "# No known bugs\n",
      "\n",
      "# Lines of code (underneath code comment and before assert statement) are taken from this project's main iPython Notebook\n",
      "\n",
      "# Test that all conflicts starting prior to 1990 were removed\n",
      "def test_1():\n",
      "    #create sample dataset: start with all zeros and make 15 years pre-1990\n",
      "    scad = pd.DataFrame(data=np.zeros((8000, 42)), columns=['eventid','ccode','id','countryname','startdate','enddate','duration','stday','stmo','styr','eday','emo','eyr','etype','escalation','actor1','actor2','actor3','target1','target2','cgovtarget','rgovtarget','npart','ndeath','repress','elocal','ilocal','sublocal','locnum','gislocnum','issue1','issue2','issue3','issuenote','nsource','notes','coder','ACD_questionable','latitude','longitude','geo_comments','location_precision'])\n",
      "    scad.styr = 1995\n",
      "    scad.styr[0:15] = 1987\n",
      "    \n",
      "    #code\n",
      "    scad = scad[scad.styr>=1990]\n",
      "    \n",
      "    #test assert\n",
      "    assert len(scad) == 7985\n",
      "\n",
      "# Test that all conflicts that exceed one calendar year were removed\n",
      "def test_2():\n",
      "    #create sample dataset: start with all zeroes amd make 15 conflicts exceed one year\n",
      "    scad = pd.DataFrame(data=np.zeros((8000, 42)), columns=['eventid','ccode','id','countryname','startdate','enddate','duration','stday','stmo','styr','eday','emo','eyr','etype','escalation','actor1','actor2','actor3','target1','target2','cgovtarget','rgovtarget','npart','ndeath','repress','elocal','ilocal','sublocal','locnum','gislocnum','issue1','issue2','issue3','issuenote','nsource','notes','coder','ACD_questionable','latitude','longitude','geo_comments','location_precision'])\n",
      "    scad.styr = 1995\n",
      "    scad.eyr = 1995\n",
      "    scad.styr[0:15] = 1987\n",
      "    \n",
      "    #code\n",
      "    scad = scad[scad.styr == scad.eyr]\n",
      "    \n",
      "    #test assert\n",
      "    assert len(scad) == 7985  \n",
      "\n",
      "# Test all duplicated rows were removed    \n",
      "def test_3():\n",
      "    #create sample dataset: start with zeroes and then remove all duplicates (all but first row are the same)\n",
      "    scad = pd.DataFrame(data=np.zeros((8000, 42)), columns=['eventid','ccode','id','countryname','startdate','enddate','duration','stday','stmo','styr','eday','emo','eyr','etype','escalation','actor1','actor2','actor3','target1','target2','cgovtarget','rgovtarget','npart','ndeath','repress','elocal','ilocal','sublocal','locnum','gislocnum','issue1','issue2','issue3','issuenote','nsource','notes','coder','ACD_questionable','latitude','longitude','geo_comments','location_precision'])\n",
      "    \n",
      "    #code\n",
      "    scad = scad.drop_duplicates(cols='eventid')\n",
      "    \n",
      "    #test assert\n",
      "    assert len(scad) == 1\n",
      "\n",
      "#Test code to determine the dominant religion\n",
      "def test_4():\n",
      "    #create sample dataset: all zeros with only one religion having any members for any given record\n",
      "    wrp = pd.DataFrame(data=np.zeros((16, 18)), columns=['year', 'state', 'chrstgen', 'judgen', 'islmgen', 'budgen', 'zorogen', 'hindgen', 'sikhgen', 'shntgen', 'bahgen', 'taogen', 'jaingen', 'confgen', 'syncgen', 'anmgen', 'nonrelig', 'othrgen'])\n",
      "    wrp.chrstgen[0]=100\n",
      "    wrp.judgen[1]=100\n",
      "    wrp.islmgen[2]=100\n",
      "    wrp.budgen[3]=100\n",
      "    wrp.zorogen[4]=100\n",
      "    wrp.hindgen[5]=100\n",
      "    wrp.sikhgen[6]=100\n",
      "    wrp.shntgen[7]=100\n",
      "    wrp.bahgen[8]=100\n",
      "    wrp.taogen[9]=100\n",
      "    wrp.jaingen[10]=100\n",
      "    wrp.confgen[11]=100\n",
      "    wrp.syncgen[12]=100\n",
      "    wrp.anmgen[13]=100\n",
      "    wrp.nonrelig[14]=100\n",
      "    wrp.othrgen[15]=100\n",
      "    wrp.year[15] = 700 #pass in a year that is larger than the largest religion (should be ignored)\n",
      "    wrp.state[9]=19643 #pass in a state that is larger than the largest religion (should be ignored)\n",
      "        \n",
      "    #code\n",
      "    yearState = wrp[['year', 'state']]\n",
      "    wrp = wrp.ix[:,2:]\n",
      "    wrp['domRel'] = wrp.idxmax(axis=1)\n",
      "    wrp = pd.DataFrame(wrp.domRel)\n",
      "    wrp=pd.merge(yearState, wrp, left_index=True, right_index=True)\n",
      "    \n",
      "    #test assert\n",
      "    np.testing.assert_array_equal(wrp.domRel, np.array(['chrstgen', 'judgen', 'islmgen', 'budgen', 'zorogen', 'hindgen', 'sikhgen', 'shntgen', 'bahgen', 'taogen', 'jaingen', 'confgen', 'syncgen', 'anmgen', 'nonrelig', 'othrgen']) )\n",
      "\n",
      "# Test setting values as NaN    \n",
      "def test_5():\n",
      "    #create sample dataset: start with zeroes, set 15 events as -99 (the code for missing)\n",
      "    scad = pd.DataFrame(data=np.zeros((8000, 42)), columns=['eventid','ccode','id','countryname','startdate','enddate','duration','stday','stmo','styr','eday','emo','eyr','etype','escalation','actor1','actor2','actor3','target1','target2','cgovtarget','rgovtarget','npart','ndeath','repress','elocal','ilocal','sublocal','locnum','gislocnum','issue1','issue2','issue3','issuenote','nsource','notes','coder','ACD_questionable','latitude','longitude','geo_comments','location_precision'])\n",
      "    scad.npart[0:15] = -99\n",
      "    \n",
      "    #code\n",
      "    scad.npart = scad['npart'].astype(float)\n",
      "    scad.npart[scad.npart == -99] = np.nan\n",
      "    \n",
      "    #test assert\n",
      "    assert np.isnan(scad.npart).sum() == 15\n",
      "    \n",
      "    \n",
      "# Test recoding of a string level variable as numeric codes (used for dominant religion)\n",
      "def test_6():\n",
      "    #create sample dataset: \n",
      "    scad = pd.DataFrame(data=np.repeat(('a','b','c','d'), 2000), columns=['domRel'])\n",
      "    \n",
      "    #code\n",
      "    levels = dict([(val, i) for i, val in enumerate(set(scad.domRel))])\n",
      "    scad['domRelNum'] = [levels[val] for val in scad.domRel]\n",
      "    \n",
      "    #test assert\n",
      "    np.testing.assert_array_equal( scad['domRelNum'], np.repeat((0,2,1,3), 2000)) \n",
      "    \n",
      "# Test coding of death/nodeath indicator variable\n",
      "def test_7():\n",
      "    #create sample dataset: start with zeroes, set 4752 events as 1 death\n",
      "    #since death variable is 0/1, it should equal the coded death/nodeath indicator\n",
      "    scad = pd.DataFrame(data=np.zeros((8000, 42)), columns=['eventid','ccode','id','countryname','startdate','enddate','duration','stday','stmo','styr','eday','emo','eyr','etype','escalation','actor1','actor2','actor3','target1','target2','cgovtarget','rgovtarget','npart','ndeath','repress','elocal','ilocal','sublocal','locnum','gislocnum','issue1','issue2','issue3','issuenote','nsource','notes','coder','ACD_questionable','latitude','longitude','geo_comments','location_precision'])\n",
      "    scad.ndeath[1:4752] = 1\n",
      "    \n",
      "    #code\n",
      "    scad['death01']=scad.ndeath\n",
      "    scad.death01[scad.death01>0] = 1\n",
      "    scad.death01[scad.ndeath == np.nan] = np.nan\n",
      "    \n",
      "    #test assert\n",
      "    np.testing.assert_array_equal(scad.ndeath, scad.death01)\n",
      "\n",
      "#test binning code in figure 2\n",
      "def test_8():\n",
      "    #create dummy data: all zeros but 1 in the other bins\n",
      "    scad = pd.DataFrame(data=np.zeros((8000, 1)), columns=['ndeath'])\n",
      "    for i in ((1,2,3,4,7,20,75, 150, 2000)):\n",
      "        scad.ndeath[i] = i\n",
      "    \n",
      "    #code\n",
      "    noNan = scad.ndeath[~np.isnan(scad.ndeath)]    \n",
      "    counts = col.Counter(noNan)\n",
      "    bins = np.arange(0, 10, 1)\n",
      "    freqs = [0]*len(counts)\n",
      "    j=0\n",
      "    for i in np.unique(counts):\n",
      "        freqs[j] = counts[i]\n",
      "        j = j+1\n",
      "    \n",
      "    freqs = np.array(freqs)\n",
      "    histFreqs = [0]*10\n",
      "    c = np.unique(counts)\n",
      "    histFreqs[0] = freqs[c==0]\n",
      "    histFreqs[1] = freqs[c==1]\n",
      "    histFreqs[2] = freqs[c==2]\n",
      "    histFreqs[3] = freqs[c==3]\n",
      "    histFreqs[4] = freqs[c==4]\n",
      "    histFreqs[5] = np.sum(freqs[(c>=5) & (c<=10)])\n",
      "    histFreqs[6] = np.sum(freqs[(c>=11) & (c<=50)])\n",
      "    histFreqs[7] = np.sum(freqs[(c>=51) & (c<=100)])\n",
      "    histFreqs[8] = np.sum(freqs[(c>=101) & (c<=200)])\n",
      "    histFreqs[9] = np.sum(freqs[(c>=201) & (c<=5000)])\n",
      "    \n",
      "    #test assert\n",
      "    np.testing.assert_array_equal(histFreqs, np.array((7991,1,1,1,1,1,1,1,1,1)) )    \n",
      "    \n",
      "#test latitude/longitude round and duplicate drop iused in n figure 6\n",
      "def test_9():\n",
      "    #create dummy data\n",
      "    scad = pd.DataFrame(data=np.zeros((8000, 3)), columns=['latitude', 'longitude', 'death01'])\n",
      "    scad.death01[0:4000] = 1\n",
      "    \n",
      "    #code\n",
      "    noNan = scad[['longitude', 'latitude', 'death01']]\n",
      "    noNan.longitude = np.round(noNan.longitude, decimals=0)\n",
      "    noNan.latitude = np.round(noNan.latitude, decimals=0)\n",
      "    noNan = noNan.drop_duplicates()\n",
      "    \n",
      "    #test assert\n",
      "    assert len(noNan) == 2\n",
      "\n",
      "#test cross validation doesn't pull the same rows\n",
      "def test_10():\n",
      "    #create dummy data: zeros with a 1:8000 counter in event id\n",
      "    scad = pd.DataFrame(data=np.zeros((8000, 42)), columns=['eventid','ccode','id','countryname','startdate','enddate','duration','stday','stmo','styr','eday','emo','eyr','etype','escalation','actor1','actor2','actor3','target1','target2','cgovtarget','rgovtarget','npart','ndeath','repress','elocal','ilocal','sublocal','locnum','gislocnum','issue1','issue2','issue3','issuenote','nsource','notes','coder','ACD_questionable','latitude','longitude','geo_comments','location_precision'])\n",
      "    scad.eventid = np.arange(1, 8001, 1)\n",
      "        \n",
      "    #code\n",
      "    np.random.seed(13)\n",
      "    crossVal = [False] * (len(scad))\n",
      "    numTest = int(0.3*len(scad))\n",
      "    crossVal[0:numTest] = [True] * numTest\n",
      "    crossVal = np.random.permutation(crossVal)\n",
      "    train = scad[~crossVal]\n",
      "    test = scad[crossVal]\n",
      "    \n",
      "    #test assert\n",
      "    assert len(np.intersect1d(train.eventid, test.eventid)) == 0\n",
      "    \n",
      "#test code to create individual dummy variables from categoricals\n",
      "def test_11():\n",
      "    #generate all zeroes and then three single instances of 1, 2, 3\n",
      "    #dummies will drop the lowest case (here the 7997 zeroes) so we need to test for one '1' indicator in each of the 3 new variables for 1-3\n",
      "    test = pd.DataFrame(data=np.zeros((8000, 42)), columns=['eventid','ccode','id','countryname','startdate','enddate','duration','stday','stmo','styr','eday','emo','eyr','etype','escalation','actor1','actor2','actor3','target1','target2','cgovtarget','rgovtarget','npart','ndeath','repress','elocal','ilocal','sublocal','locnum','gislocnum','issue1','issue2','issue3','issuenote','nsource','notes','coder','ACD_questionable','latitude','longitude','geo_comments','cinc'])\n",
      "    test.etype[0:3] = np.arange(1,4,1)\n",
      "    \n",
      "    #code\n",
      "    v = test[['ndeath', 'locnum', 'cgovtarget', 'etype', 'issue1', 'cinc']]\n",
      "    v = v[~np.isnan(v).any(1)]\n",
      "    dummies = pd.get_dummies(v.etype, prefix='etype')\n",
      "    v = v.drop('etype', 1)\n",
      "    v = v.join(dummies.ix[:, 1:])\n",
      "    \n",
      "    #test assert\n",
      "    assert sum(v['etype_1.0'])==1\n",
      "    assert sum(v['etype_2.0'])==1\n",
      "    assert sum(v['etype_3.0'])==1\n",
      "    \n",
      "#test computing model prediction error\n",
      "def test_12():\n",
      "    #generate a model with a perfect fit (use OLS and pass a matrix of all 0).  prediction error should be 0\n",
      "    #train/test split already tested; dummy generation already tested\n",
      "    #only other untested things in this modeling process is the modeling itself, which is a packaged function and is assumed to have been tested by the developer\n",
      "    v = pd.DataFrame(data=np.zeros((8000, 5)), columns=['ndeath', 'locnum', 'cgovtarget', 'etype', 'cinc'])\n",
      "    v['intercept'] = 1.0\n",
      "    modp2 = sm.OLS(v.ndeath, v[v.columns[1:]], missing='drop')\n",
      "    modp2 = modp2.fit()\n",
      "    \n",
      "    #code\n",
      "    ests = modp2.predict(v[v.columns[1:]])\n",
      "    true = v[['ndeath']].values\n",
      "    mspe2 = np.sum(np.square(true-ests))\n",
      "    \n",
      "    #test assert\n",
      "    assert mspe2==0\n",
      "#test creation of prediction accuracy chart (code for logit regression)\n",
      "def test_13():\n",
      "    #use the perfect fit model generated above\n",
      "    v = pd.DataFrame(data=np.zeros((8000, 5)), columns=['ndeath', 'locnum', 'cgovtarget', 'etype', 'cinc'])\n",
      "    v['intercept'] = 1.0\n",
      "    modp2 = sm.OLS(v.ndeath, v[v.columns[1:]], missing='drop')\n",
      "    modp2 = modp2.fit()\n",
      "    \n",
      "    #code\n",
      "    ests = modp2.predict(v[v.columns[1:]])\n",
      "    true = v[['ndeath']].values\n",
      "    predAnalysis = [[0 for x in xrange(2)] for x in xrange(2)]\n",
      "    for i in range(0,len(true),1):\n",
      "        if true[[i]]==0 and ests[[i]]==0:\n",
      "            predAnalysis[0][0] = predAnalysis[0][0] + 1\n",
      "        elif true[[i]]==0 and ests[[i]]==1:\n",
      "            predAnalysis[0][1] = predAnalysis[0][1] + 1\n",
      "        elif true[[i]]==1 and ests[[i]]==0:\n",
      "            predAnalysis[1][0] = predAnalysis[1][0] + 1\n",
      "        elif true[[i]]==1 and ests[[i]]==1:\n",
      "            predAnalysis[1][1] = predAnalysis[1][1] + 1\n",
      "\n",
      "    #test assert (all are predicted correctly as zeros, so we know what the matrix should look like)\n",
      "    np.testing.assert_array_equal( predAnalysis, np.array([[8000,0],[0,0]]) )\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting boyas_test.py\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!nosetests boyas_test.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "......."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".\r\n",
        "----------------------------------------------------------------------\r\n",
        "Ran 13 tests in 1.396s\r\n",
        "\r\n",
        "OK\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}